{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6xyabwiXxFG",
        "outputId": "73188a62-8c58-4f21-ce55-5599bae19129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "import pandas \n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK13B7u8XxFM"
      },
      "outputs": [],
      "source": [
        "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsNfm8biXxFO"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBWAD7vnXxFQ",
        "outputId": "4b26f484-798b-46a9-d156-9204e38bad4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "data = pandas.read_csv('https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz', sep='\\t', on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRdqBdn4XxFQ"
      },
      "source": [
        "## Keep Reviews and Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "FTIU1Wf9XxFR"
      },
      "outputs": [],
      "source": [
        "#Remove null value rows and reset index\n",
        "data = data.dropna()\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "#Keep only review_body column and corresponding star_rating column\n",
        "data = data[['review_body', 'star_rating']]\n",
        "\n",
        "#Removing all non-integer star_rating\n",
        "data['star_rating'] = data['star_rating'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUrWJqfmXxFR"
      },
      "source": [
        " ## We select 20000 reviews randomly from each rating class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "H-AjWdinXxFS"
      },
      "outputs": [],
      "source": [
        "sample_size = 20000\n",
        "dataset = pandas.DataFrame()\n",
        "for i in data.star_rating.unique():\n",
        "    X = data[data.star_rating == i].sample(sample_size)\n",
        "    dataset = dataset.append(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2do0ziFXxFT"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN029xsDXxFU"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0fVL0XUXxFU",
        "outputId": "4f84e9bd-9868-4014-992c-c4e177f02520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average character length before cleaning:  189.45369\n",
            "Average character length after cleaning:  172.96123\n"
          ]
        }
      ],
      "source": [
        "X, Y = dataset['review_body'].tolist(), dataset['star_rating'].tolist()\n",
        "\n",
        "#Print the average character length of the reviews before cleaning\n",
        "character_length_bf_cl = 0\n",
        "for i in range(len(X)):\n",
        "  character_length_bf_cl += len(X[i])\n",
        "print('Average character length before cleaning: ', character_length_bf_cl/len(X))\n",
        "\n",
        "#Convert reviews to lower case\n",
        "X = list(map(lambda x: str(x).lower(), X))\n",
        "\n",
        "#Remove HTML and URLs from reviews\n",
        "X = list(map(lambda x: re.sub('<.*>', '', x), X))\n",
        "X = list(map(lambda x: re.sub(r'https?://\\S+', '', x), X))\n",
        "\n",
        "#Remove non-alphabetical characters\n",
        "X = list(map(lambda x: re.sub('[^a-z ]', '', x), X))\n",
        "\n",
        "#Remove extra spaces\n",
        "X = list(map(lambda x: re.sub(' +', ' ', x), X))\n",
        "\n",
        "#Expand contractions\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "def decontraction(s):\n",
        "    for word in s.split(' '):\n",
        "        if word in contractions.keys():\n",
        "            s = re.sub(word, contractions[word], s)\n",
        "    return s\n",
        "X = list(map(decontraction, X))\n",
        "\n",
        "#Print the average character length of the reviews after cleaning\n",
        "character_length_af_cl = 0\n",
        "for i in range(len(X)):\n",
        "  character_length_af_cl += len(X[i])\n",
        "print('Average character length after cleaning: ', character_length_af_cl/len(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-11zcHnXxFV"
      },
      "source": [
        "## remove the stop words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb53QYUpXxFV",
        "outputId": "3bd745b0-4710-416a-e99e-8aae5bcfc55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average character length before pre-processing:  172.96123\n"
          ]
        }
      ],
      "source": [
        "#Print the average character length of the reviews before pre-processing\n",
        "character_length_bf_pp = 0\n",
        "for i in range(len(X)):\n",
        "  character_length_bf_pp += len(X[i])\n",
        "print('Average character length before pre-processing: ', character_length_bf_pp/len(X))\n",
        "\n",
        "# remove stop words\n",
        "stopWords =set(stopwords.words('english'))\n",
        "def rmstopWords(s):\n",
        "    wordlist = s.split(' ')\n",
        "    newlist = []\n",
        "    for word in wordlist:\n",
        "        if word not in stopWords:\n",
        "            newlist.append(word)\n",
        "    s = ' '.join(newlist)\n",
        "    return s\n",
        "\n",
        "X = list(map(rmstopWords, X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFb-5XL4XxFW"
      },
      "source": [
        "## perform lemmatization  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErMk4l6MXxFW",
        "outputId": "257ca451-5d93-4818-8339-43d417780f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average character length after pre-processing:  105.73715\n"
          ]
        }
      ],
      "source": [
        "# perform lemmatization\n",
        "wnl = WordNetLemmatizer()\n",
        "X = list(map(lambda x: ' '.join(map(wnl.lemmatize, x.split(' '))), X))\n",
        "\n",
        "#Print the average character length of the reviews after pre-processing\n",
        "character_length_af_pp = 0\n",
        "for i in range(len(X)):\n",
        "  character_length_af_pp += len(X[i])\n",
        "print('Average character length after pre-processing: ', character_length_af_pp/len(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMICNcPTXxFW"
      },
      "source": [
        "# TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "A5od7nzKXxFX"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "#Splitting data into training and testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(tfidf, Y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp4ibGKoXxFX"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6JGzT74XxFX",
        "outputId": "db047cce-b913-4088-f856-263b833c1d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5165441176470589 , 0.48821047406304297 , 0.5019777976266429 \n",
            "\n",
            "0.2964793082149475 , 0.24552429667519182 , 0.26860660324566316 \n",
            "\n",
            "0.3016611295681063 , 0.33922789539227893 , 0.3193434935521688 \n",
            "\n",
            "0.3430073126142596 , 0.378562421185372 , 0.3599088838268792 \n",
            "\n",
            "0.5761752399704652 , 0.5736339132565548 , 0.5749017681728881 \n",
            "\n",
            "0.40814774645856994 , 0.40655 , 0.4064048666113688 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(X_train, Y_train)\n",
        "\n",
        "Y_test_predict = perceptron.predict(X_test)\n",
        "\n",
        "report = metrics.classification_report(Y_test, Y_test_predict, output_dict = True)\n",
        "#print(report)\n",
        "print(report['1']['precision'], ',', report['1']['recall'], ',', report['1']['f1-score'], '\\n')\n",
        "print(report['2']['precision'], ',', report['2']['recall'], ',', report['2']['f1-score'], '\\n')\n",
        "print(report['3']['precision'], ',', report['3']['recall'], ',', report['3']['f1-score'], '\\n')\n",
        "print(report['4']['precision'], ',', report['4']['recall'], ',', report['4']['f1-score'], '\\n')\n",
        "print(report['5']['precision'], ',', report['5']['recall'], ',', report['5']['f1-score'], '\\n')\n",
        "print(report['weighted avg']['precision'], ',', report['weighted avg']['recall'], ',', report['weighted avg']['f1-score'], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCO0SPqPXxFX"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V74xQgZ7XxFY",
        "outputId": "64c1c94b-a4d1-4226-dba3-a01eac54b5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.554019014693172 , 0.6363862000496401 , 0.5923530091255631 \n",
            "\n",
            "0.3709090909090909 , 0.3391304347826087 , 0.35430861723446894 \n",
            "\n",
            "0.3991017964071856 , 0.3320049813200498 , 0.36247450713800133 \n",
            "\n",
            "0.4367816091954023 , 0.40252206809583857 , 0.4189526184538654 \n",
            "\n",
            "0.6121174266083698 , 0.7204116638078902 , 0.6618640252138677 \n",
            "\n",
            "0.4757340583338357 , 0.48795 , 0.47947431661900564 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm = LinearSVC()\n",
        "svm.fit(X_train, Y_train)\n",
        "\n",
        "Y_test_predict = svm.predict(X_test)\n",
        "\n",
        "report = metrics.classification_report(Y_test, Y_test_predict, output_dict = True)\n",
        "#print(report)\n",
        "print(report['1']['precision'], ',', report['1']['recall'], ',', report['1']['f1-score'], '\\n')\n",
        "print(report['2']['precision'], ',', report['2']['recall'], ',', report['2']['f1-score'], '\\n')\n",
        "print(report['3']['precision'], ',', report['3']['recall'], ',', report['3']['f1-score'], '\\n')\n",
        "print(report['4']['precision'], ',', report['4']['recall'], ',', report['4']['f1-score'], '\\n')\n",
        "print(report['5']['precision'], ',', report['5']['recall'], ',', report['5']['f1-score'], '\\n')\n",
        "print(report['weighted avg']['precision'], ',', report['weighted avg']['recall'], ',', report['weighted avg']['f1-score'], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnAV9okxXxFY"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eme3xs9jXxFY",
        "outputId": "6a346af6-ae7e-41c4-80f4-d68540453d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5929531757070005 , 0.634896996773393 , 0.613208677933597 \n",
            "\n",
            "0.3906331763474621 , 0.38184143222506395 , 0.3861872736678738 \n",
            "\n",
            "0.42608222161720666 , 0.38978829389788294 , 0.4071279916753382 \n",
            "\n",
            "0.46931696905016007 , 0.4436317780580076 , 0.45611305587968365 \n",
            "\n",
            "0.6531622777402656 , 0.7111002205341828 , 0.680900985452839 \n",
            "\n",
            "0.5076750610988537 , 0.51385 , 0.5101237039104157 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "logistic = LogisticRegression(solver = 'saga')\n",
        "logistic.fit(X_train, Y_train)\n",
        "\n",
        "Y_test_predict = logistic.predict(X_test)\n",
        "\n",
        "report = metrics.classification_report(Y_test, Y_test_predict, output_dict = True)\n",
        "#print(report)\n",
        "print(report['1']['precision'], ',', report['1']['recall'], ',', report['1']['f1-score'], '\\n')\n",
        "print(report['2']['precision'], ',', report['2']['recall'], ',', report['2']['f1-score'], '\\n')\n",
        "print(report['3']['precision'], ',', report['3']['recall'], ',', report['3']['f1-score'], '\\n')\n",
        "print(report['4']['precision'], ',', report['4']['recall'], ',', report['4']['f1-score'], '\\n')\n",
        "print(report['5']['precision'], ',', report['5']['recall'], ',', report['5']['f1-score'], '\\n')\n",
        "print(report['weighted avg']['precision'], ',', report['weighted avg']['recall'], ',', report['weighted avg']['f1-score'], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkxTqi4PXxFY"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLqeLJaGXxFY",
        "outputId": "ac760af8-2f5a-4e74-8a54-52502ef08094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5929531757070005 , 0.634896996773393 , 0.613208677933597 \n",
            "\n",
            "0.3906331763474621 , 0.38184143222506395 , 0.3861872736678738 \n",
            "\n",
            "0.42608222161720666 , 0.38978829389788294 , 0.4071279916753382 \n",
            "\n",
            "0.46931696905016007 , 0.4436317780580076 , 0.45611305587968365 \n",
            "\n",
            "0.6531622777402656 , 0.7111002205341828 , 0.680900985452839 \n",
            "\n",
            "0.5076750610988537 , 0.51385 , 0.5101237039104157 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, Y_train)\n",
        "\n",
        "Y_test_predict = mnb.predict(X_test)\n",
        "\n",
        "Y_test_predict = logistic.predict(X_test)\n",
        "\n",
        "report = metrics.classification_report(Y_test, Y_test_predict, output_dict = True)\n",
        "#print(report)\n",
        "print(report['1']['precision'], ',', report['1']['recall'], ',', report['1']['f1-score'], '\\n')\n",
        "print(report['2']['precision'], ',', report['2']['recall'], ',', report['2']['f1-score'], '\\n')\n",
        "print(report['3']['precision'], ',', report['3']['recall'], ',', report['3']['f1-score'], '\\n')\n",
        "print(report['4']['precision'], ',', report['4']['recall'], ',', report['4']['f1-score'], '\\n')\n",
        "print(report['5']['precision'], ',', report['5']['recall'], ',', report['5']['f1-score'], '\\n')\n",
        "print(report['weighted avg']['precision'], ',', report['weighted avg']['recall'], ',', report['weighted avg']['f1-score'], '\\n')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}